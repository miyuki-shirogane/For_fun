➡️20190430:
大致接口测试框架搭建完成，用时1.5d。
目前情况是：解决了token写入获取，放在headers去请求各种接口。尚能跑通，但尚存许多不足，比如：
1.测试用例设计过于单一，目前全是关于status校验（不难，在于经验积累及思路拓展）
2.测试报告自动输出（不难，有ui自动化的模板现成可用，但还需要稍稍优化）
3.与数据库相关联，通过接口对测试数据进行基础的增删改查，与数据库sql执行结果拿来比对；此处是核心内容，较有难度（涉及内容主要有：
数据库动作封装、测试用例分离管理等）

➡️20190505:
1.测试数据库数据初始化及之后接口测试、html格式测试报告输出功能完成；
包括数据库一些表清空、数据插入动作的封装，框架更清晰；
2.清空表数据采用的sql是：truncate table tabel_name cascade;把握不是很大，可能存在隐患；
（
location:readDB_config.py-line37~38；
mysql_exp:cursor.execute("SET FOREIGN_KEY_CHECKS = 0;")
											）

➡️20190506:
1.5号提到的隐患发生了，后果较严重，control+b一秒内org表外键关联的表数据全部删光，导致测试环境系统无法使用；怕了怕了，这部分先不调用；待有了更好的办法后再说
（目前想想方案：就搞个测试服，就我一人用，数据就那几个，也就不需要数据初始化了。。但比较麻烦，因为这样以后每次迭代更新都要在两台服务器进行部署）
2.又新写了几个接口测试用例；

➡️20190509:
今天在写安卓测试用例，没搞脚本

➡️20190508:
1.org_tree这块的查询获取需要满足不同组织返回下设架构数量不一样，故需要三个账号及其token，所以login重复三遍，已解决；另，最近这个token
原来一直没执行，因为我压根没把他写进主函数，导致最近执行一直用的之前写好的token，而不是登录获取新的token，说实话，有点蠢；但是也发现了
一个问题：token可以一直用？不会失效？？？这我觉得是隐患，改日跟孙雨讨论下；
2.好了最近可能接口自动化脚本的进度需要暂搁，因为要测安卓了。。

➡️20190509：
1.token的问题也别改日了，昨晚就跟孙雨说了；他说token有效期是1天，那我决定再观察两天，同一个token隔天还能不能用。能用就直接提bug了；
2.上午开了半天的会，主要是本周工作内容回顾、之后工作安排；我这边决定还是下午开始测安卓app，得空再进行api测试脚本的开发。
估摸得下礼拜了，这礼拜要做也就一丢丢。。礼拜6要去趟医院看胃病，晚上皮卡丘走一波；
3.今天测完了安卓；问题已经跟xiandiao大致说了

➡️20190510
1.上午测了token的问题，果然有问题，已经放jira上了，sunyu已知悉；
2.下午开会，有之后工作安排，及jira初次使用；1-3断网，发了0.5h呆。。。；另外，4.30会议结束后还有1.5小时，继续测接口吧；但是，这个post接口返回的结果实在令人confusing。。研究下吧；(找了sunyu哥哥，一秒解决。原来url最后必须'/'结尾，否则好像转get了)
3.关于下一个sprint计划：安卓测试缺陷回归测试、预约访客用例评审/执行/缺陷回归测试、看产品进度进行下一个sprint的需求分析用例编辑、接口测试脚本编辑
(btw,皮卡丘挺萌的，但除去这个，剧情什么的并不好看

➡️20190513
1.关于数据初始化外键约束的解决办法周末时候想到了一个替代方案：
即，在使用post方法发送请求后形成的测试数据，使用一定的命名规范，那么在使用delete方法测试的时候，直接使用封装的数据库操作，找出post形成的新纪录，获取id，再删除；此时就会有一举两得的效果：post、delete方法全测完，然后还不会在数据库残留过多的测试数据；
2.上述方法在一般的数据表中确实行得通；但是device表采用的是软删除方法，那么在delete以后，后续的get方法就会有404的情况。故而又封装了一个硬删除的方法，在delete以后执行，问题完美解决（另，该删除函数命名需介于delete和get之间，这里给他命名ele（饿了）（笑））
（接下来计划三个工作日完成全部接口自动化测试脚本；）

➡️20190514
1.完成了大部分的接口测试脚本，主要碰到的问题有：后面很多业务相关数据表都有link关系，那么在操作表数据的时候，会受到外键约束带来的许多困扰；很多数据采用的软删除方法导致get方法下会报错；表外键约束下数据删除碰到的一些数据库报错；

➡️20190515
1.今天碰到的问题是：get一定时间戳范围结果是否符合要求，这里为应对的处理逻辑是：提取返回的结果json，提取其中“start”数据，即记录生成的时间戳，将其注入一个新的列表。然后逐个判断该列表元素是否在我请求的时间戳范围内，若是，在另一个新列表内注入数据‘1’，否则注入‘0’，然后对该列表元素进行求积，若求积结果为1，则通过，为0，则失败
2.终于到了visitor的接口测试的脚本编辑了，但是碰到了一个问题，目前的知识盲区吧。。x-signature，见都没见过，怀疑是visitor提交信息时的一个身份令牌校验；关于其获取的方法,I don't have any clue..正在尽力google中。

➡️20190516
1.关于x-signature，进行了了解。其本质就是服务端算法加工形成的加密字符串，我这里无法实时获取。故这块就不在此处接口自动化脚本体现了；（后续提测在网页进行业务功能测试）
2.今天上午搞了预约访客用例的熟悉，摘要提炼；下午计划写完visitor模块的全部接口用例，试跑成功；
（下面是一些总结：
3.下午确实写完了全部接口测试基础用例；这里我为什么说基础用例，因为目前设计的用例全是跑通为主，同时关注一些接口的数据联动。还没有考虑参数多样化及一些异常情况；但是作为本阶段的接口测试自动化还是较为成功的。实现了接口数据联动、框架搭建；
计划中期，在本次预约访客模块迭代结束后，会陆续添加前面提及的参数多样化及一些异常情况。另，预约访客模块脚本编写结束后，还不能试跑，因为代码暂时还未布到1.5测试环境。请求路径会出问题；
至于后期计划，我这边的想法是：优化脚本框架、结构、添加一些必要附属优化功能；
；；；（假装有分割线）
待访客功能完全开发结束后，（包括后面的黑名单、临时访客等功能）开始设计主干业务流程的ui自动化脚本。这里说明一下，千万不要想利用ui自动化遍历所有业务支线及按钮。只能考虑主干业务流程操作没有问题；其价值与接口自动化脚本异曲同工，都是为了后期迭代开发回归测试考虑，执行的次数越多，其带来的价值越高；

➡️20190517
1.今日は楽しい日です，上午用例评审、工作札记补充，下午weekly会议、调试visitor接口自动化测试脚本、用例评审、茶话会；下班。

➡️20190520
访客用例执行

➡️20190521
访客用例执行；bug提交

➡️20190522-20190523
attendance需求熟悉、用例框架编辑；attendance尚未召开功能知照会，后面也没说要开，好在需求尚且好懂，有个别问题问下siming；计划在下周二用例设计完毕，能进行评审

➡️20190524
attendance用例设计完毕

➡️20190527
visitor功能回测、attendance接口文档熟悉

➡️20190528
常客功能测试用例设计、attendance用例补充、visitor缺陷修复check
计划本周完成attendance用例评审、测试数据部署/visitor回测、发布/常客用例评审/下周开始做attendance功能测试及接口自动化脚本编辑

➡️20190529
sick leave

➡️20190530
visitor bug修复check回测；attendance、常客用例评审、需求模糊点确认、用例修改、补充
计划下周开始测attendance；

➡️20190531
attendance1.5测试环境没有部署的情况下，实在不好直接写代码，因为调试难度会加大很多；还没有到能盲写到程度。故暂计划等部署好以后进行调试编写。
上午开了访客saas的需求评审会，已了解；

➡️20190603
访客saas平台用例整理设计、attendance测试数据准备；别骗自己了 今天tmd发了一下午呆。。惭愧惭愧，但是现在没活啊 attendance还没布

➡️20190604
突然想到，部署attendance测试数据的时候，可以先准备点测试数据，放到其他无关紧要的月份。观察是否和预期一样，再做调整。然后导入正式的测试数据。
今天导入了测试数据，中途报了许多错。好在最后还是导入成功了；holiday\shift card测试完毕，bug整理过；考勤数据还是没有，孙雨处理中；导测试数据中做的处理认为有风险，例如remarks字段删除后，attendance表格备注怎么办。。

➡️20190605
测试数据导入完成，attendance测试结束，bug已整理；昨天提到的隐患并没有发生

➡️20190606
缺陷整理过了一下；jira上已经登入；下午开始准备着手写attendance的接口冒烟用例；

➡️20190613
0607--0612的工作札记懈怠了；具体每天做了什么实在记不起，总结下吧，本周主要工作内容为访客saas测试用例设计、attendance缺陷回归验证。另外attendance接口自动化脚本也在持续的开发中；接口文档中的有些参数传递会出现问题，以及web中部分操作会抛异常，故个人感觉还是放一放，等bug都修复以后统一开发接口脚本会比较好；用例评审。。emm。。。看产品啥时候有空；（目前开发进度来看，可以不着急 慢慢来）
碰到一点点问题：
创建shift card接口的时候，做了往shift\punch time插数据的操作；
shift:id /name /apply_to
punch time:id /name /shift_id
member:id /apartment /job_level

就是说 我新建member的时候，有auto_apartment\auto_joblevel，然后新建shift的时候， 会在apply_to中关联member里的这俩字段
（那么好，我从member表里取这俩的时候，必然要找没有建shift的member。这时候在create_shift的时候，apply_to字段中填写的内容要从member中查询获取目前shift中没有的数据；这里不用顾虑，因为创建必在删除之前，即：创建member1、创建member2➡️创建shift（挂靠member2）➡️删除member1➡️删除shift➡️get一些shift、punch time，怕麻烦就get非auto的信息，反正只是get，没所谓了）

以上是昨天的思路，睡了一觉今天想想，到那里的时候 往member表里插入仿生人misaka10086,当新建shift的时候 apply_to就填这个。最后调用delete_member接口删掉该仿生人



➡️20190617
开始研究服务器性能压测：

本次计划性能测试还是在测试服务器上执行，意味着没跑性能测试的时候，服务器几乎空载。而线上服务器，一般不会处于空载的状态。
故如果只是让脚本起多个线程，跑一次脚本，貌似没有什么说服力。因为当服务器从空载瞬间升到满负荷状态，服务器很大的一部分开销可能就消耗在创建线程上，而不是在处理业务上。
因此，性能测试，我对其分析结果是：不能让服务器空转，应该时刻反复运行某接口脚本

场景模拟：比如，模拟若干个用户在线，可能就会分配一部分用户浏览进出记录，一部分用户在创建访客，一部分用户在下线/上线等。也或者模拟流量不均匀的情况，某一时刻100用户在线，过一会降到50用户在线，再过一会又升到150用户在线，在这样的情况，看系统的性能情况等等。

我理想中的报告，是出错率随时间推移、线程数增加的一条曲线 关注2个点：第一次出错、出错率突然暴增；另，tps。亦关注2个点：最佳点、极限点

重点测试接口：record的新增，即人脸识别记录新增（因员工一天最多需要打卡4次，有些人会担心自己没打上，多打几次，假设每次打卡1.5次，4次就是6次；访客进出假设至少打卡2次，假设平均3次，陌生人假设日均出现1000例；那么一个3000员工的大厂，设其每天会生成23000-25000条访问记录）；登录每天可能访问300-500次；其他接口：创建访客（一天大概接待300-500名访客？）
根据打卡规律 会在上下班高峰期频繁调用create memrecord接口，根据上述数据分析，我这里设计的是：30分钟内打卡5000-6000次，6小时循环一次

；；；；；另，所有list接口在3分钟内360的响应时间关注
============================================================================
bug work flow整理：
状态：open invalid worksforme later duplicate inprogress resolved close reopen

说明：bug种类按照等级优先，其实可以被分为bug和优化（优化其实可以认为是优先级较低的bug，即等级在major以下；有些甚至可以不在本期解决，而是消化到下期的需求中）

流程：
1.当问题创建时，其状态为“open”；

2.接下来召开bug知照会议（通常是迭代第一轮测试结束后，目的是将bug内容过一下，后面解决bug的时候在现象理解上更轻松；与会人员包括产品和所有开发。时长30-45min），会议上，会将bug分配给对应经办人。这时候bug状态会出现以下分支：
	(a.如果出现个别bug在会议上被指出就是这么设计的，不是bug，则需要一个新的状态“invalid”（并备注原因）。
	(b.如果该问题偶然出现，无规律可循，或者需要长时间观察其稳定性以规避风险，或者压根无法重现，则需要一个新的状态“worksforme”（适用情况：无法复现,查看源码无法找到原因，若有更多关于这个bug的线索,再重新接受这个bug）
	(c.不在本期解决的major以下问题，可以新建一个状态“later”
	(d.如果与之前某个问题形成原因相同，or甚至重复，需要一个新的状态“duplicate”（目前阶段不太可能出现，但是鉴于jira问题创建后无法删除，如果以后人员新增or意外重复，可以有一个状态来归类这种bug），并关联被重复的bug。
	(e.其他本期需要解决的问题全部为默认“open”

3.上述b、c、e在正常or特定条件下将会进入下一个状态：“in progress”➡️“resolved”

4.接下来是“closed”或者是“reopen”

相较开发任务的workflow，这里的设计少了todo\testing，原因：
1.状态过多，大多数情况下bug周期较短，过多的状态会很繁琐
2.这里新建时默认的open状态，等同于todo
3.因为bug登记的主要目的是为了我这里跟踪方便，testing状态个人认为没有太大必要，可以直接进入close或者reopen状态；

➡️20190618
压测接口参数配置结束，碰到问题用了次级方法解决，但至少有用；但是压测循环次数，执行时间，线程数量暂时没有头绪；毕竟新开始研究这个，碰到问题也是自然，尽力克服吧。最少拿出点研究成果、测试数据来；
下午开了workflow的讨论会议，耗时75min，已有初步结果；

➡️20190619
今天早上是访客saas的用例评审，有了另外两处前面没想到的用例设计思路及一处纠偏；

关于性能压测，有了下列思路：
请求的接口为login\create member_record\list所有接口，共计12个。目前已有的数据是300线程在60秒内启动并请求12个接口，是为极限，再新增线程将会出现error
根据这个思路，我需要的结果数据包含以下4点：
1.默认服务器硬件条件（测试服务器）下，正常的请求频率，线程极限是多少？
2.保证较好的请求响应时间，最佳线程是多少？
3.正常生产环境下的线程数量条件下，能承受多大的请求频率？
4.模拟摸索出一个线程数、请求频率最佳的一个平衡点，并连续运行，观察其稳定性（这里规定其时长8小时）


➡️20190620
今天设计了登录线程 200 起步，运行时长30min，下设十个list请求，循环控制器设置循环10次；依照50 为粒度往上新增线程。发现到达350线程时出现了报错信息；故因此定论300线程为极限；300是否足够有待定论
-----也可以得出，最多开放300个用户在一个服务器；
接下来，是创建到访记录接口压测；创建50线程，每个30分钟内请求1000次，共计5w次，响应时间正常，无异常，认为无再往上压的必要，足以应付生产环境的需求；
再接下来是稳定性测试，我会把主要的、经常调用的接口放在一起，运行时长8小时，线程设置300，观察异常率；

今天时间不够明天再弄；（下午准备好明天稳定性测试的用例，以及周会汇报：系统压力、稳定性测试；attendance 已修复bug验证，接口自动化脚本编辑

➡️20190621
稳定性测试 启动。
从稳定性角度考虑，300个虚拟用户 在8小时内陆续启动，且每个虚拟用户以每小时20*11请求数的速率发送请求；测试结果：在2小时的时间点，出现error，认为300用户量稳定性不足。
接下来，下放线程数为250，继续稳定性测试。1.5小时时间点，响应时间开始飙升到无法忍受的地步，并开始出现错误。认为250用户量稳定性不足。
接下来，继续下放线程到200，进行进一步的稳定性测试：依旧不行，200线程下 还是这样的请求频率，在1.5小时时间点，memrecord数据量来到了5000条，但是在这种请求频率下，这个接口请求效率就会很低；我一旦关了压力测试工具，停止发送请求，页面刷新不会出现问题。但是这种请求速率下 就会很慢了。

为什么一个线程请求的时间也要5、6秒，而页面上请求响应时间只要1、2秒（不过这也跟为什么生产环境进出记录上万条也这么快对上了），这个不得而知；不过 在前面说的并发请求速率下，请求响应时间确实很慢了。所以，认为在这种数据记录条件下，请求响应时间急需优化。响应时间折线图放在jmeter；


➡️20190701
sprint2完成时间节点理解为重测结束时间点；7.15之前还要做完性能测试报告，并在此前编辑一份转正报告。
开会 看bug 更新压测用例；明天更新新需求用例、问下sp1的更新代码是否布上去了。好了就验一下；


➡️20190704
测完vm_sprint2，上线成功；

➡️20190705

本次重构系统压力测试从两个维度进行测试：1.压力并发测试。2.稳定性测试。其中压力测试选用的重点接口是生产环境中调用次数最多的创建进出记录接口；因为尤其在attendance模块开发结束后，业务层面存在每人每天至少打卡4次的情况。那么对于上千人的大厂来说，该接口的承受并发压力能力显得尤为重要；
case1：
配置参数如下：
运行次数1次，运行时间1s，线程数起步150，粒度10；逐级往上压。极限280 ；够生产压力需求了；然后，我觉得 瓶颈在数据库。。。

case2:
接下来模拟数万条进出记录情况下，进出记录并发浏览的响应时间，抑或是否会出现服务崩溃情况；❌
-无法测试，现在该接口感觉崩了；

case3：
最后做稳定性测试；也是最难的一条。完美情况下 希望无限逼近生产环境的运作场景，同时负载空间上大大超出生产需求。⌛️
配置参数如下：
50线程
登录1次
各页面循环切换及创建进出记录（循环100）
循环次数：永远
运行时长7200s

-testing ，2小时手动结束压测。最后聚合报告中个别几个请求失败导致error。看了结果树 response message显示原因为socket closed，即与压测无关。是因为手动停止导致的请求中止。故结论是稳定性通过✅
聚合报告及响应时间折线图见desktop


attack affence

➡️20190708
上午开需求讲解会；下午压测报告编辑，还差一个接口没法访问，在看；

➡️20190709
这比我想象的来的复杂；部门管理、权限管理、职位/职介管理、还涉及分公司，认为有必要弄公司架构。这些，在现有的系统中都是没有的。
那我这里的理解是：假定这些东西是有的or不久未来会做的，即数据是有来源的，若暂时没有，或者说交付测试版本的时候没有这个东西，那么大不了这一块不测，业务逻辑的理解上反正没有错误及偏差；

➡️20190710
我理解的模版下载，是默认那些字段的下载，除姓名、手机号必填以外，其他随意；那这样就失去自定义和批量导入的意义了；

➡️20190714
jira上对于单个bug的记录、描述、流程已经较完善；需要的是一次迭代结束以后的list，能够直观的看到本轮迭代有哪些bug。
我理想的bug list，除了包含bug罗列
	（bug名称 描述（操作步骤 预期/实际结果） 紧急程度 预期解决时间点 是否验证通过）
以外，还包括以下统计信息：
	bug主要发生在哪些模块功能、总数、解决率、wont_do_bug的开发备注原因；（这也是我之前python脚本爬自家jira实现的一个功能）
要更漂亮的话 可能还需要一些图表，给其他角色看；


➡️20190715
稳定性测试还需要往上压 目前150并发已pass；明儿个压一下100的。 2分法 懂的 找到那个稳定性瓶颈；100也pass了 兄弟(100没有pass 继续；)




电话
1.自我介绍+项目介绍（一轮迭代为例，测试工作流程 表达清晰）;5min

2.你认为一个合格的测试用例 该怎么写 包含哪些要素（元素齐全，特征正确）
用例名称 编号 前置条件 操作步骤 预期结果 测试数据 执行情况 测试目的 执行时间 执行人 ;3min

列举一个你印象较深的corner case//（有点答非所问 开始结巴）

3.功能测试在 beta 版本对外的上线标准是什么;2min（//缺陷级别高的不应存在；风险把控 时间紧急主干功能不能受影响）

4.get和post的区别是什么（以你的理解 尽可能的列举；列举5条及以上即可）;3min；
	a.GET在浏览器回退时是无害的，而POST会再次提交请求。
	b.GET产生的URL地址可以被Bookmark，而POST不可以
	c.GET请求会被浏览器主动cache，而POST不会，除非手动设置
	d.GET请求只能进行url编码，而POST支持多种编码方式
	e.GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
	-f.GET请求在URL中传送的参数是有长度限制的，而POST么有
	g.对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
	-h.GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
	-i.GET参数通过URL传递，POST放在Request body中
	j.GET产生一个TCP数据包；POST产生两个TCP数据包（并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次)


5.某个查询返回的结果与你预期不同，你会怎么报这个bug；3min（//这里逻辑有点不清晰）
（正常来说 先定位问题原因#定位的过程很重要，看看定位问题的思路
然后提给开发 bug内容包含名称 操作步骤 预期结果 实际结果 经办人 严重等级 创建时间 解决状态 预期完成时间）

6.某个查询预期返回结果数量为5000条，实际返回4999条。你会怎么定位这个问题的原因？;3min
核实需求 确保查询无误；二分 找到异常数据 与其他数据比对 与开发核实查询条件逻辑 （经验来说 只差一条一般不会是需求理解有问题 大多数情况是逻辑异常（比如重名这种）或者某条件遗漏（比如is_valid这种字段限制）） 
（//逻辑不太清楚。。）


7.说下左连接和右连接（数据库）;2min（wrong）

8.查看实时日志 创建新文件（linux）;1min

9.详细描述下python做接口自动化测试的框架，关于数据初始化怎么做 或者甚至不做？/（自动化’）;5min

10.python生成随机数用哪个方法;1min

11.python列表、元组的区别：
列表属于可变序列，他的元素可以随时修改或删除；元组属于不可变序列，其中的元素不可以修改，除非整体替换。
列表可以使用append()、extend()、insert()、remove()、pop()等方法实现添加和修改列表元素，而元组没有这几个方法，所以不能想元祖中添加和修改元素。同样，元组也不能删除元素。
列表可以使用切片访问和修改列表中的元素。元组也支持切片，但是他只支持通过切片访问元素，不支持修改。
元组比列表的访问和处理速度快，所以只是需要对其中的元素进行访问，而不进行任何修改时，建议使用元组。
;3min

12.jmeter动态获取其他接口返回参数使用什么元件（后置处理器-正则表达式提取器）（//wrong）

13.既然有管理经验 一轮迭代 你是怎么测试分工的？;5min（按模块 给任务 日反馈 通过excel表格整理 发给开发 以及测试主管 ）
------------------------------------------------------------------

1.python实现一个某脚本定时跑的小功能 会怎么写（2）;10min

2.某个查询接口 返回的一串结果（可能有数十条,假设已经处理为一个列表）要测试是不是全部在给定区间内 要求返回断言结果true or false 你会怎么写 python（2）;10min

3.怎么准备接口自动化的测试数据 谈一下思路（2）;10min

4.既然掌握jmeter，那么我如果要做一个系统稳定性的测试 测试的用例设计策略或者思路是怎样（2）;15min

5.描述下微信朋友圈发小视频的用例设计（2）;15min


➡️20190718
rnm今天太困了 卵状态没有 发了一天呆 下午开会压测报告丢出来秀了秀 数据很详尽了；
第三期工作任务总结：attendance回归测试、访客saas测试、压力测试报告、id_management用例设计；



➡️20190723
准备优化下现在接口测试脚本的框架；预想引入ddt(data driver test)数据驱动,数据初始化还是要做
到时候研究研究数据驱动的框架怎么搞 结合现在已有的框架 修改修改 ；现有的框架模式总感觉是不健康的 不能这么下去。。。

➡️20190725
今天开了一天的会。


➡️20190729
要解决的问题如下：
1.目录优化&目录跳转
2.新增ddt用例管理
已收藏，后续研究一哈

➡️20190730
目录结构大改，且分离了数据查询和数据初始化；又添加了2个功能：
1.定时启动的开关switch
2.循环读取存在excel的case方法 ExcelUtil

➡️20190731
接口自动化用例设计的思路、持续集成；
1 输入

　　输入参数主要从以下几各方面设计：

　　a 必填项校验

　　接口文档中有是否必填的说明。参考接口文档即可。

　　b 参数长度校验

　　参考接口文档即可。

　　c 参数值的有效性校验

　　如：身份证号的校验 ，设计的数据虽然符合身份证号的规则，但是并不是真实有效的身份证号；这种情况就要看身份证号的校验规则是什么样了，一般都是用的现成的身份证号校验器，但是有些是自己写的校验算法，这个本人就遇到过这种问题—校验算法写的不正确；

　　所以参数有效性的校验就需要结合实际业务场景，判断哪些数据是真实有效的数据，一定要确保所有真实有效的数据是可以验证通过的。

　　d 参数组合校验

　　不同的参数组合可能会存在不同的业务场景；

　　e 如果参数是枚举值，一定要各种枚举值都要测试，因为可能不同的枚举走的不同的业务流程；

　　f 参数值的默认值的校验

　　参考接口文档。

　　g 某些参数具有特定的生成规则，要单独针对生成规则设计用例，一定要保证真实有效的数据是可以验证通过的。


2 接口逻辑

　　接口逻辑我用的设计方法是分支覆盖—>路径覆盖—>场景覆盖,同样也是要结合实际业务场景，根本不发生的业务场景就是无效的测试用例。

　　a 第一步先把业务流程图画出来；

　　b 依据路程图中的分支分别设计，不同分支不同的场景，这里就要把异常的场景考虑进去；如接口超时，接口异常，接口请求成功或失败，成功后怎么处理，失败后流程是否继续执行，失败后的数据怎么处理；

3 输出

输入结果：正常输出和异常输出，常用的方法有错误推断法（列举出程序中可能存在的错误或者异常，根据他们选择测试用例）

4 以上都完成后，要结合实际的业务场景去掉冗余的用例（即实际业务场景不存在的流程或者输入数据）；

5 如果业务流程涉及到状态转换，要单独设计用户—方法：状态转换图；

6 涉及到多个不同金额或者手续费的计算，可能还会用到正交实验法去设计用例；

7 另外，用例设计中还应当包含异常流程中产生的异常数据的处理流程；—通常所说的补偿机制，这块流程能大大的减轻人工运营的工作量，当然，这需要在做系统设计的时候就需要把这部分考虑进去。

Ewa

➡️20190813
权限管理、通行记录：能测的都测完了；梳理了下访客需求；明天计划看能不能更新一下测试环境，先验一下已解决的问题

➡️20190814
今天整理出访客模块主干流程的测试用例；

➡️20190816
0812 在“我的访客”里创建的预约审核状态即为“允许访问”；
0812 部分账号组（如访客管理员）创建的新预约审核状态即为 允许访问；





➡️20190822

公司A：管理员x、员工a
公司B：管理员y、员工b
一般访客c

1.员工a在web端“我的访客”创建event：c访问a（已允），发送邮件，内含二维码；
那c会收到邮件，扫码进入小程序，看到自己的访问信息（或需要补充信息，补充完才有二维码哦）or取消，签到一次过后还可以发起再次访问
而a自己进入小程序，会看到这条访问信息，可取消or再次邀请（订阅消息通知，会收到小程序通知）

2.管理员x在web端“访客列表”创建event：c访问a（已允），发送邮件，内含二维码；
那c会收到邮件，扫码进入小程序，看到自己的访问信息（或需要补充信息，补充完才有二维码哦）or取消，签到一次过后还可以发起再次访问
而a自己进入小程序，会看到这条访问信息，可取消or再次邀请（订阅消息通知，会收到小程序通知）

看看c

创建路径还有：a在小程序创建c访问a、c发起了再次访问

同理a访问b，然后都搞完以后看下b这个双重身份 


管理员创建不全信息的访问事件➡️


➡️20190902
黑名单、车辆管理测试；bug提交。

➡️20190906
账户组权限测试，access版本发布






1\2\3\6

/工号重复提示信息需要中文
/新增员工，账号大小写未处理























藤原萌叶 白银圭 
藤原千花 白银御行
四宫辉夜
终生 彻底
who whould have fucking thought

